---
title: "Data mining text mining assignment"
Editor: "Zhengdong Li"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.


##Load the packages
```{r}

if (!require('dplyr')) install.packages('dplyr'); library(dplyr)
if (!require('tidytext')) install.packages('tidytext'); library(tidytext)
if (!require('textdata')) install.packages('textdata'); library(textdata)
if (!require('stringr')) install.packages('stringr'); library(stringr)
if (!require('tidyr')) install.packages('tidyr'); library(tidyr)
if (!require('ggplot2')) install.packages('ggplot2'); library(ggplot2)
if (!require('scales')) install.packages('scales'); library(scales)
if (!require('igraph')) install.packages('igraph'); library(igraph)
if (!require('ggraph')) install.packages('ggraph'); library(ggraph)
if (!require('widyr')) install.packages('widyr'); library(widyr)
if (!require('topicmodels')) install.packages('topicmodels'); library(topicmodels)

if (!require('readr')) install.packages('readr'); library(readr)



if (!require('wordcloud2')) install.packages('wordcloud2'); library(wordcloud2)

```
##Load the data
```{r}

amazon_data <- read.csv("C:/Users/Administrator/Desktop/archive/Amazon_Unlocked_Mobile.csv")
str(amazon_data)
```
##Exploratory Analysis

##create a new data frame which contains "Brand.Name" and their own count "n"
```{r}

data1 <- amazon_data %>% count(Brand.Name, sort = TRUE) %>%
    filter(n > 3000)%>%
    filter(Brand.Name != "NA") %>%
    filter(Brand.Name != "") %>%
    mutate(Brand.Name = reorder(Brand.Name,n))


```



##Display the brand name of the phones which have more than 3000 sales
```{r}
BrandName <- c(data1$Brand.Name)
count <- c(data1$n)

brand_count <- ggplot(data = data1, aes(x = BrandName, y = count , fill = BrandName)) + geom_bar(stat = 'identity') + theme(text = element_text(size = 7))
plot(brand_count)

```

```{r}

amazon_data%>%
  count(Product.Name, sort = TRUE)

```




##Descriptive statistic

##Tokenization
```{r}
tidy_texts <- amazon_data %>%
  unnest_tokens(word, Reviews)


```


## Word counts 
```{r}
tidy_texts %>%
  count(word, sort = TRUE)
```
## filter the stop words
```{r}

data(stop_words) #load the stop words dataset

tidy_texts <- tidy_texts %>% anti_join(stop_words)

## count the word frequency again
tidy_texts %>%
  count(word, sort = TRUE)

```
##Inspect NUll value
```{r}
inspectdf::inspect_na(tidy_texts)
```

##Filter the Null values
```{r}
tidy_texts_Without_NA <- tidy_texts %>% filter(word != "NA")
tidy_texts_Without_NA %>% count(word, sort = TRUE)


```
##Visualization of the words that appear at least 10000 times
```{r}

tidy_texts_Without_NA %>% count(word, sort = TRUE)%>%
  filter(n > 10000) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) + geom_col()+
  xlab(NULL)+
  ylab("Frequency")+
  coord_flip()+
  theme(text = element_text(size = 8))



```
```{r}
cloud <- tidy_texts_Without_NA %>% count(word, sort = TRUE)
names(cloud) <- c("word", "frequency")
wordcloud2(cloud, color = "random-dark", backgroundColor = "black")
```
##Sentiment analysis using lexicons, load the lexicons
```{r}
afinn <- get_sentiments("afinn") #vocabulary of sentiment score of  each word
bing <- get_sentiments("bing") #sentiment type of each word(negative or positive)
nrc <- read_csv("d:/Downloads/nrc.csv") # emotion types of each word (anger, joy, fear...)
```
## Display those words related to "trust" category
```{r}

nrc_trust <- nrc %>%
  filter(sentiment == "trust")

```
##Display the frequency of the words related to "trust" category
```{r}
 tidy_texts_Without_NA %>%
  inner_join(nrc_trust) %>%
  count(word, sort = TRUE)

```
##report the tf-idf score of words related to "trust" by brand
```{r}
brand_words_trust <-tidy_texts_Without_NA %>%
  inner_join(nrc_trust) %>%
  count(Brand.Name, word, sort = TRUE)
```
```{r}
brand_words_trust<- brand_words_trust %>% bind_tf_idf(word,Brand.Name,n)
plot_trust_words <- brand_words_trust %>% 
  filter(Brand.Name == "Samsung" | Brand.Name == "Apple" | Brand.Name == "BLU" | Brand.Name == "LG" | Brand.Name == "HUAWEI" | Brand.Name =="Sony" )
plot_trust_words
```
##Visualize the words related to "trust" by brand name based on ti-idf value 
##According to the TF-IDF plots,  we can say, for example, people trust the HUAWEI mate series, or we can say people trust Apple is perfect, excellent...
##"Compact" is quite an important word for Sony
```{r}

plot_trust_words  %>%
  arrange(desc(tf_idf)) %>%
  mutate(word=factor(word, levels = rev(unique(word)))) %>%
group_by(Brand.Name) %>%
  top_n(10) %>%
  ggplot(aes(word,tf_idf, fill = Brand.Name)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Brand.Name, ncol = 2, scales = "free") +
  coord_flip()



```



##Display the sentiment score of each Brand using bing lexicon
```{r}

text_sentiment <- tidy_texts_Without_NA %>% inner_join(get_sentiments("bing")) %>%
  count(word, index = Brand.Name,  sentiment) %>%
  spread(sentiment,n, fill=0) %>%
  mutate(sentiment=positive-negative)

```

```{r}

ggplot(text_sentiment, aes(word, sentiment, fill = index)) + theme(axis.text.x = element_blank())+
  geom_col(show.legend = FALSE)

```

##Display top 5 words for certain brands based on lexicon "bing"
##positive words take up a large proportion in each brands have high sentiment words like "excellent", "love", "happy", "fast"
```{r}
text_sentiment %>%
  filter(index == "Huawei" | index == "Apple" | index == "Samsung" | index == "Sony" | index == "Nokia" |   index == "HTC") %>%
  mutate(word=factor(word, levels = rev(unique(word)))) %>%
  group_by(index) %>%
  top_n(6) %>%
  ggplot(aes(word,sentiment, fill = index)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~index, ncol = 2, scales = "free") +
  coord_flip()
  
```

## Report words from Bing dictionary by count

```{r}


bing_word_counts <- tidy_texts_Without_NA  %>% inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE)
bing_word_counts

```

##Display the top 5 negative and positive words
##From the top5 negative words, th epotential problem of some brands will be "bad", "slow" and son on.
```{r}
bing_word_counts %>% group_by(sentiment) %>%
  top_n(5) %>%
  ungroup %>%
  mutate(word = reorder(word,n)) %>%
  ggplot(aes(word, n, fill=sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  coord_flip()
```
##sentiment analysis based on lexicon "Afinn"
```{r}

afinn_word_count <- tidy_texts_Without_NA %>% inner_join(get_sentiments("afinn")) %>%
  count(word, value, Brand.Name, sort = TRUE) %>% 
  filter(value > -3) %>% #keep the words range from -2 to 2
  filter(value < 3) %>%
  filter(Brand.Name == "Samsung" | Brand.Name == "Apple" | Brand.Name == "LG" | Brand.Name == "HUAWEI") #select 4  companies
afinn_word_count


```

##Display the top 10 frequent words  by brand names  based on afinn value
##According to the plots below, people who bought these 4 brands will be more likely to recommend it
Explanation examples
##Top 10 frequent words for HUAWEI have all positive afinn value, it is pretty, easy to use, worthy, solid and bright and so on
##People might be dissapointed with Samsung or feel negative about its "pay" activity, but they think it smart, worthy, recommended
##consumer might beworried about its Apple devices would be stolen
```{r}

afinn_word_count  %>%
  arrange(desc(n)) %>%
  mutate(word=factor(word, levels = rev(unique(word)))) %>%
group_by(Brand.Name) %>%
  top_n(10) %>%
  ggplot(aes(word,value, fill = Brand.Name)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Brand.Name, ncol = 2, scales = "free") +
  coord_flip()

```



## Report the most frequent words by Brand name

```{r}
brand_words<- tidy_texts_Without_NA  %>%
  count(Brand.Name, word, sort=TRUE)
brand_words

```

##Tf-idf numbers of Samsung ,Apple, Nokia, HUAWEI
```{r}
brand_words<- brand_words  %>% bind_tf_idf(word,Brand.Name,n)
plot_words <- brand_words %>% 
  filter(Brand.Name == "Samsung" | Brand.Name == "Apple" | Brand.Name == "HUAWEI" | Brand.Name == "Sony")
plot_words


```
## Visualize words by Brand name based on the tf-idf value
## TF-IDF is more indicative than TF
## "Mate" serie is important word for HUAWEI
##"iphone" is an important word for Apple
##"galaxy" serie is important for Samsung
```{r}
plot_words  %>%
  arrange(desc(tf_idf)) %>%
  mutate(word=factor(word, levels = rev(unique(word)))) %>%
group_by(Brand.Name) %>%
  top_n(10) %>%
  ggplot(aes(word,tf_idf, fill = Brand.Name)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Brand.Name, ncol = 2, scales = "free") +
  coord_flip()
```
##Tokenization by bigram
```{r}
amazon_bigrams <- amazon_data %>% unnest_tokens(bigram, Reviews, token ="ngrams", n = 2) 


```

##Display the bigram frequency
```{r}

amazon_bigrams %>% count(bigram, sort = TRUE)

```

##Filter NA and display the frequency again
```{r}


amazon_bigrams_noNA <-  amazon_bigrams %>% 
  filter(bigram != "NA")%>%
  count(Brand.Name,bigram, Rating, sort = TRUE)

```

##Package for removing stop words
```{r}

if(!require("tm")) install.packages("tm") ; library("tm")
```


##Filter the stop words in bigram
```{r}
bigrams_separated<- amazon_bigrams_noNA %>%
  separate(bigram, c("word1","word2"), sep=" ")
```

```{r}
#remove the stop words for word1 and word2 respectively, c1, c2 are word1,word2 after being processed
clean_bigram <- bigrams_separated %>% 
  mutate(c1 = removeWords(word1, stopwords("en"))) %>%
  mutate(c2 = removeWords(word2, stopwords("en")))

clean_bigram <- clean_bigram %>%
  filter(c1 != "") %>%
  filter(c2 != "")
```

##unite the bigram
```{r}
bigram_united <- clean_bigram %>% unite(bigram, c1, c2, sep = " ")
bigram_united <- subset(bigram_united, select = -c(word1,word2)) ## drop unused columns

bigram_united
```
##TF-IDF score for bigram
```{r}
bigram_tf_idf <- bigram_united  %>% 
  bind_tf_idf(bigram, Brand.Name,n) %>% 
  arrange(desc(tf_idf))
```

##Filter and group bigrams by certain brands
```{r}

plot_bigram_tf_idf <- bigram_tf_idf %>%
  filter(Brand.Name == "Samsung" | Brand.Name == "Apple" | Brand.Name == "HUAWEI" | Brand.Name == "BLU")
```

##Tf-idf bigrams Visualization for certain brands
##Accrong to the plots, we observe that mate 7 is an important product for HUAWEI; People like brand new product from Apple; Note 4 is important product for Samsung and so on......
```{r}
plot_bigram_tf_idf %>%
  arrange(desc(tf_idf)) %>%
  mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>% 
  group_by(Brand.Name) %>% 
  top_n(15, tf_idf) %>% 
  ungroup %>%
  ggplot(aes(bigram, tf_idf, fill = Brand.Name)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~Brand.Name, ncol = 2, scales = "free") +
  coord_flip()+theme(text = element_text(size = 10))
```

##lexicon based sentiment analysis by bigram
```{r}
negation_words <- c("not", "no", "never", "without", "don't", "doesn't", "can't", "couldn't")
AFINN <- get_sentiments("afinn")

```

## Report the number of words with negation words based on Affin lexicon
```{r}

negated_words <- bigrams_separated %>% 
  filter(word1 %in% negation_words) %>% 
  inner_join(AFINN, by = c(word2 = "word")) %>%
  mutate(value_true = -value) %>%
  unite(bigram, word1, word2, sep = " ") 


negated_words <- subset(negated_words, select = -c(value)) #drop column "value", because the value of the bigrams should be changed, if word1 is a negated word
negated_words
```
##Display the phrases with negated words by 4  brands
##Although each brand has a higher contribution for "no problem" in their own graph,  people are more likely to buy Apple and Samsung
```{r}

negated_words %>% 
  mutate(contribution = n * value_true) %>% 
  arrange(desc(abs(contribution))) %>% 
  filter(Brand.Name == "Samsung" | Brand.Name == "Apple" | Brand.Name == "BLU" | Brand.Name == "LG") %>%
  head(60)%>%
  ggplot(aes(bigram, n * value_true,fill = n * value_true > 0)) +
  geom_col(show.legend = FALSE) +
  xlab(" words with negated words") +
  ylab("Sentiment score * frequency") +
  facet_wrap(~Brand.Name, ncol = 2, scales = "free") +
  coord_flip()+theme(text = element_text(size = 10))
```
##Negated bigram based on TF-IDF
```{r}

negated_tf_idf <- negated_words  %>% 
  bind_tf_idf(bigram, Brand.Name,n) %>% 
  arrange(desc(tf_idf))

```

##Visualize top 10 words with negated words by 4 certain brands based on TF-IDF
##From the result, we observe, for example,   some consumers might think their Apple products have no problems or no advantages,  some might think their HUAWEI are not bright or have no lag, some think their Samsung have no problem or they have no regret buy it...
```{r}

negated_tf_idf %>%
  filter(Brand.Name == "Samsung" | Brand.Name == "Apple" | Brand.Name == "HUAWEI" | Brand.Name == "BLU") %>%
  arrange(desc(tf_idf)) %>%
  mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>% 
  group_by(Brand.Name) %>% 
  top_n(10, tf_idf) %>% 
  ungroup %>%
  ggplot(aes(bigram, tf_idf,fill = Brand.Name)) +
  geom_col(show.legend = FALSE) +
  xlab(" words with negated words") +
  ylab("TF-IDF score") +
  facet_wrap(~Brand.Name, ncol = 2, scales = "free") +
  coord_flip()+theme(text = element_text(size = 10))
  
```



##Topic modelling based on bigrams
```{r}

by_brand<- bigram_united %>% group_by(Brand.Name) %>% 
  unite(document,Brand.Name) 
```

##prepare document-term matrix
```{r}

amazon_document_term_matrix <- by_brand %>% cast_dtm(document, bigram, n)

```

##LDA modelling based on bigram of amazon , k controls topic numbers
```{r}

amazon_LDA <- LDA(amazon_document_term_matrix, k = 6, control = list(seed=425))

```

Beta probabilities for each bigram
```{r}

Betas <- tidy(amazon_LDA, matrix="beta")
Betas
```

##Top best bigrams for the topics based on Betas
```{r}
amazon_top_terms <- Betas %>% group_by(topic) %>% top_n(22, beta) %>% 
  ungroup() %>% 
  arrange(topic, desc(beta))
amazon_top_terms
```


## Plot the best  bigrams by topics
##Topic 1 is about "htc phone", topic 2 is about "blu phone", Topic 3 is about "iphone",  topic4 is about "Wifi", topic5 is about "Samsung", topic 6 is about "nexus 5".

```{r}

amazon_top_terms %>% 
  mutate(term=reorder(term,beta)) %>% 
ggplot(aes(term,beta, fill=factor(topic)))+
  geom_col(show.legend = FALSE)+
  facet_wrap(~topic,scales = "free")+
  theme(text= element_text(size = 7))+
  coord_flip()
```
## Gamma probabilities
```{r}
amazon_gamma <- tidy(amazon_LDA, matrix="gamma")

```

##Gamma probabilities for Samsung ,Apple, BLU, LG
```{r}
amazon_gamma1 <- amazon_gamma %>%
  filter(document == "Samsung" | document == "Apple" | document == "BLU" | document == "LG")
```

##relevant Topics for Apple, BLU, Samsung, LG
## According ro  the plots, each brand belongs to a certain topic, for example Apple belongs to topic3, meaning it's a greate phone, works perfectly, its shipping is fast and so on
```{r}

amazon_gamma1 %>%
ggplot(aes(factor(topic),gamma)) +
  geom_boxplot() +
  facet_wrap(~document)
```
##Gamma probabilities for Nokia, MEIZU, HUAWEI, HTC
```{r}
amazon_gamma2 <- amazon_gamma %>%
  filter(document == "Nokia" | document == "MEIZU" | document == "HUAWEI" | document == "HTC")

```

##Relavent topics for  Nokia, MEIZU, HUAWEI, HTC
```{r}
amazon_gamma2 %>%
ggplot(aes(factor(topic),gamma)) +
  geom_boxplot() +
  facet_wrap(~document)
```


